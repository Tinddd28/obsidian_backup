## Модель нейрона

![[Pasted image 20241121152131.png]]

нейрон — это базовый вычислительный элемент, вдохновленный биологическим нейроном в человеческом мозге. Его задача — принимать на вход значения, производить над ними вычисления и передавать результат дальше по сети.

- **Структура нейрона:**
    - Нейрон получает несколько входных сигналов x1,x2,…,xnx_1, x_2, \dots, x_nx1​,x2​,…,xn​.
    - Каждый вход xix_ixi​ умножается на соответствующий вес wiw_iwi​, который регулирует важность этого входа.
    - Сумма взвешенных входов передается через функцию активации, чтобы сделать результат нелинейным.


- **Вес** (wiw_iwi​) — это параметр, который определяет, насколько сильно каждый входной сигнал влияет на выход нейрона.
## Активационная функция

![[Pasted image 20241121152224.png]]

![[Pasted image 20241121152241.png]]

В зависимости от функций выполняемых нейронами можно выделить три типа нейронов: 
	• входные нейроны, на которые подается входной вектор, кодирующий входное воздействие; как правило, в них не выполняются вычислительные процедуры; 
	• выходные нейроны – выходы ИНС; 
	• промежуточные (скрытые) нейроны – основа ИНС. 
 Соответственно можно выделить три типа слоев: входной, скрытые и выходной. 
 В целом вид выполняемого сетью преобразования обусловлен не только характеристиками исходных нейронов, но и особенностями архитектуры сети, а именно топологией межнейронных связей, способами обучения этой сети, наличием или отсутствием конкуренции между нейронами, направлением и способом управления и синхронизации, способом передачи информации между нейронами.

Без функции активации нейрон вычислял бы только линейную комбинацию входов, а нейронная сеть была бы эквивалентна линейной регрессии. Функция активации добавляет **нелинейность**, что позволяет модели решать сложные задачи.

### Примеры функций активации:

- **ReLU (Rectified Linear Unit):**
    
    f(x)=max⁡(0,x)f(x) = \max(0, x)f(x)=max(0,x)
    
    Быстро вычисляется и помогает избежать проблемы исчезающих градиентов.
    
- **Sigmoid:**
    
    f(x)=11+e−xf(x) = \frac{1}{1 + e^{-x}}f(x)=1+e−x1​
    
    Ограничивает значения выхода в диапазоне (0,1)(0, 1)(0,1).
    
- **Tanh (гиперболический тангенс):**
    
    f(x)=ex−e−xex+e−xf(x) = \frac{e^x - e^{-x}}{e^x + e^{-x}}f(x)=ex+e−xex−e−x​
    
    Значения находятся в диапазоне (−1,1)(-1, 1)(−1,1), что полезно для централизованных данных.
## Виды
![[Pasted image 20241121152519.png]]
![[Pasted image 20241121152534.png]]


## Виды обучения
- Обучение с учителем предполагает, что для каждого входного вектора существует целевой вектор, представляющий собой требуемый выход. Вместе они называются обучающей парой. Обычно сеть обучается на некотором числе таких обучающих пар. Предъявляется входной вектор, вычисляется выход сети и сравнивается с соответствующим целевым вектором, разность (ошибка) с помощью обратной связи подается в сеть, и веса изменяются в соответствии с алгоритмом, стремящимся минимизировать ошибку. Векторы обучающего множества предъявляются последовательно, вычисляются ошибки, и веса подстраиваются для каждого вектора до тех пор, пока ошибка по всему обучающему массиву не достигнет приемлемо низкого уровня.
- Обучение без учителя не нуждается в целевом векторе для выходов и, следовательно, не требует сравнения с предопределенными идеальными ответами. Обучающее множество состоит лишь из входных векторов. Обучающий алгоритм подстраивает веса сети так, чтобы получались согласованные выходные векторы, т. е. чтобы предъявление достаточно близких входных векторов давало одинаковые выходы. Процесс обучения, следовательно, выделяет статистические свойства обучающего множества и группирует сходные векторы в кластеры. Предъявление на вход вектора из данного кластера даст определенный выходной вектор, но до обучения невозможно предсказать, какой выход будет производиться данным кластером входных векторов. Следовательно, выходы подобной сети должны трансформироваться в некоторую понятную форму, обусловленную процессом обучения.

## Персепртрон
это однослойная нейронная сеть с нейронами имеющими пороговую активационную функцию.
![[Pasted image 20241121152751.png]]

## Доп вещи
### RELU
![[Pasted image 20241121153311.png]]
![[Pasted image 20241121153331.png]]


## По коду:
### Для полносвязной
### **`rmsprop` (Root Mean Square Propagation)**

- **Что это такое?** `RMSprop` — это алгоритм оптимизации, используемый для настройки весов модели во время обучения. Он является усовершенствованной версией метода градиентного спуска, который учитывает изменения градиентов в течение нескольких шагов, чтобы стабилизировать процесс обучения.
    
- **Ключевые особенности:**
    
    - Делит шаг градиентного спуска на корень среднего квадрата предыдущих градиентов.
    - Хорошо подходит для моделей с шумными градиентами или для задач с большим количеством данных.
    - Чаще используется для задач, связанных с нейронными сетями, где требуется стабильное обучение.
- **Параметры RMSprop:**
    
    - `learning_rate`: скорость обучения (по умолчанию в Keras — 0.001).
    - `rho`: коэффициент, который определяет, насколько сильно учитываются предыдущие градиенты (по умолчанию 0.9).

---

 **`mse` (Mean Squared Error)**

- **Что это такое?** `MSE` — это среднеквадратичная ошибка, которая используется как функция потерь (loss function). Она измеряет среднюю разницу между предсказанными значениями и реальными значениями в квадратах.
    
- **Формула:**
    
    MSE=1n∑i=1n(yi−y^i)2MSE = \frac{1}{n} \sum_{i=1}^{n} (y_i - \hat{y}_i)^2MSE=n1​i=1∑n​(yi​−y^​i​)2
    
    где:
    
    - yiy_iyi​ — истинные значения.
    - y^i\hat{y}_iy^​i​ — предсказанные значения.
    - nnn — количество примеров.
- **Почему используется?**
    
    - MSE подчеркивает большие ошибки больше, чем маленькие, из-за квадрата разности. Это делает модель более чувствительной к аномалиям.

---

 **`rmse` (Root Mean Squared Error)**

- **Что это такое?** `RMSE` — это квадратный корень из `MSE`. Он используется для оценки качества модели в тех же единицах измерения, что и предсказываемая величина.
    
- **Формула:**
    
    RMSE=MSE=1n∑i=1n(yi−y^i)2RMSE = \sqrt{MSE} = \sqrt{\frac{1}{n} \sum_{i=1}^{n} (y_i - \hat{y}_i)^2}RMSE=MSE​=n1​i=1∑n​(yi​−y^​i​)2​
- **Почему используется?**
    
    - RMSE удобен, потому что его значение имеет те же единицы, что и yyy.
    - Позволяет более наглядно оценить точность модели.

---

**`r2` (R-squared или Коэффициент детерминации)**

- **Что это такое?** `R2` измеряет, насколько хорошо модель объясняет изменчивость данных. Это относительная метрика качества предсказания.
    
- **Формула:**
    
    R2=1−∑i=1n(yi−y^i)2∑i=1n(yi−yˉ)2R^2 = 1 - \frac{\sum_{i=1}^{n} (y_i - \hat{y}_i)^2}{\sum_{i=1}^{n} (y_i - \bar{y})^2}R2=1−∑i=1n​(yi​−yˉ​)2∑i=1n​(yi​−y^​i​)2​
    
    где:
    
    - yiy_iyi​ — истинные значения.
    - y^i\hat{y}_iy^​i​ — предсказанные значения.
    - yˉ\bar{y}yˉ​ — среднее значение истинных данных.
- **Диапазон значений:**
    
    - R2=1R^2 = 1R2=1: Идеальная модель.
    - R2=0R^2 = 0R2=0: Модель не лучше случайного среднего.
    - R2<0R^2 < 0R2<0: Модель хуже случайного среднего.
- **Почему используется?**
    
    - `R2` показывает процент объясненной вариации в данных.
    - Хорошо подходит для оценки регрессионных моделей.

---

Пример использования в коде:

1. **Оптимизация:**
    
    - `RMSprop` используется для настройки весов модели в процессе обучения.
2. **Функция потерь:**
    
    - `MSE` используется как метрика для минимизации ошибки предсказания модели.
3. **Оценка модели:**
    
    - `RMSE` и `R2` рассчитываются на тестовых данных, чтобы измерить качество предсказаний.

### Для LSTM 

 **`optimizer='adam'`**

- Адаптивный оптимизатор градиентного спуска.
- Автоматически регулирует шаг обучения для каждого параметра.
- Хорошо работает с большими наборами данных и нерегулярными градиентами.

 **`loss='mse'`**

- Среднеквадратичная ошибка (Mean Squared Error).
- Используется для минимизации разницы между предсказанными значениями и истинными.

**`metrics=['mae']`**

- Mean Absolute Error (средняя абсолютная ошибка).
- Показывает среднюю величину абсолютной разницы между истинными значениями и предсказаниями.




## LSTM
long short time memory
![[Pasted image 20241121155743.png]]
В LSTM есть три основных вида узлов, которые называются гейтами: входной (input gate), забывающий (forget gate) и выходной (output gate), а также собственно рекуррентная ячейка со скрытым состоянием.

LSTM (Long Short-Term Memory) — это разновидность рекуррентной нейронной сети, которая эффективно решает проблему исчезающих градиентов и способна запоминать важную информацию на длительных временных интервалах.

### Двунаправленная LSTM
Двунаправленная LSTM (Bidirectional LSTM) — это модификация рекуррентной нейронной сети (RNN), которая позволяет учитывать контекст как из прошлого, так и из будущего при обработке последовательностей данных. Это особенно полезно для задач, где информация как до, так и после текущего шага важна, например, в анализе текста, речи или временных рядов.
- **Ячейка памяти (Cell):**
    - Хранит информацию, "запоминаемую" сетью.
- **Гейт-механизмы:**
    - **Входной гейт (Input Gate):** Определяет, какую новую информацию сохранить.
    - **Гейт забывания (Forget Gate):** Определяет, какую информацию удалить из памяти.
    - **Выходной гейт (Output Gate):** Определяет, что использовать для предсказания на текущем шаге.
- **Состояние ячейки (Cell State):**
    - Протекает через всю последовательность, являясь "долгосрочной памятью".
- **Скрытое состояние (Hidden State):**
    - Представляет "краткосрочную память" сети на каждом шаге.

Двунаправленное LSTM (Bidirectional LSTM) состоит из двух независимых слоёв LSTM:

1. **Прямое направление (Forward):**
    - Анализирует последовательность данных слева направо (временной порядок).
2. **Обратное направление (Backward):**
    - Анализирует ту же последовательность в обратном порядке (справа налево).

Оба направления обрабатывают данные параллельно, а их выходы объединяются (суммируются, конкатенируются или усредняются), чтобы сформировать окончательное представление.

**ПРЕИМУЩЕСТВА**
- **Учёт контекста с обеих сторон:**
    
    - Позволяет извлекать информацию как из предшествующих шагов, так и из будущих (например, соседних слов в тексте).
- **Улучшенная производительность:**
    
    - Особенно полезно для задач, где последовательность данных содержит контекстные зависимости (анализ текста, распознавание речи, временные ряды).
- **Универсальность:**
    
    - Работает с различными типами данных, включая текст, звук, биомедицинские сигналы и другие временные ряды.


## Полносвязная

Полносвязная нейронная сеть (Fully Connected Neural Network, FCNN) — это базовый тип искусственной нейронной сети, где каждый нейрон в одном слое связан с каждым нейроном следующего слоя. Она широко используется для обработки структурированных данных (таблицы, временные ряды) и служит основой для более сложных архитектур.

- **входной слой (Input Layer):**
    
    - Представляет данные, подаваемые в сеть.
    - Количество нейронов соответствует числу признаков в данных.
        - Например, если входной вектор данных имеет размер nnn, то входной слой содержит nnn нейронов.
- **Скрытые слои (Hidden Layers):**
    
    - Один или несколько слоев нейронов, находящихся между входным и выходным слоями.
    - Каждый нейрон скрытого слоя соединён с каждым нейроном предыдущего и следующего слоев.
    - **Функция активации:**
        - Для нелинейных преобразований данных, например:
            - **ReLU (Rectified Linear Unit):** f(x)=max⁡(0,x)f(x) = \max(0, x)f(x)=max(0,x)
            - **Sigmoid:** f(x)=11+e−xf(x) = \frac{1}{1 + e^{-x}}f(x)=1+e−x1​
            - **Tanh:** f(x)=ex−e−xex+e−xf(x) = \frac{e^x - e^{-x}}{e^x + e^{-x}}f(x)=ex+e−xex−e−x​
- **Выходной слой (Output Layer):**
    
    - Возвращает результат работы сети.
    - Количество нейронов зависит от задачи:
        - Для регрессии — один нейрон (числовой результат).
        - Для бинарной классификации — один нейрон с функцией активации `sigmoid`.
        - Для многоклассовой классификации — столько нейронов, сколько классов, с функцией активации `softmax`.




применение л1 л2 приводит к обновлению, градиенты тоже

не участвуют в обучении

дропаут выключает

на незнакомых данных обобщающаяся способность увеличивается


второй способ - увеличение выборки